{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e54f0d7c-69dc-4896-819e-263b14ff9b22",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pygsheets in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (2.0.5)\n",
      "Requirement already satisfied: google-api-python-client>=1.5.5 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from pygsheets) (1.6.0)\n",
      "Requirement already satisfied: google-auth-oauthlib in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from pygsheets) (0.4.6)\n",
      "Requirement already satisfied: six<2dev,>=1.6.1 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from google-api-python-client>=1.5.5->pygsheets) (1.16.0)\n",
      "Requirement already satisfied: oauth2client<5.0.0dev,>=1.5.0 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from google-api-python-client>=1.5.5->pygsheets) (4.1.3)\n",
      "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from google-api-python-client>=1.5.5->pygsheets) (3.0.1)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from google-api-python-client>=1.5.5->pygsheets) (0.15.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from oauth2client<5.0.0dev,>=1.5.0->google-api-python-client>=1.5.5->pygsheets) (0.4.8)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from oauth2client<5.0.0dev,>=1.5.0->google-api-python-client>=1.5.5->pygsheets) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from oauth2client<5.0.0dev,>=1.5.0->google-api-python-client>=1.5.5->pygsheets) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from google-auth-oauthlib->pygsheets) (1.3.0)\n",
      "Requirement already satisfied: google-auth>=1.0.0 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from google-auth-oauthlib->pygsheets) (2.3.3)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from google-auth>=1.0.0->google-auth-oauthlib->pygsheets) (57.4.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from google-auth>=1.0.0->google-auth-oauthlib->pygsheets) (4.2.4)\n",
      "Requirement already satisfied: requests>=2.0.0 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->pygsheets) (2.26.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->pygsheets) (3.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib->pygsheets) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib->pygsheets) (2.0.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib->pygsheets) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib->pygsheets) (2021.10.8)\n",
      "Requirement already satisfied: pyarrow in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (8.0.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from pyarrow) (1.20.3)\n",
      "Requirement already satisfied: google.cloud in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (0.34.0)\n",
      "Requirement already satisfied: pandas_gbq in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (0.17.5)\n",
      "Collecting pandas_gbq\n",
      "  Downloading pandas_gbq-0.17.6-py2.py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: db-dtypes<2.0.0,>=0.3.1 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from pandas_gbq) (0.3.1)\n",
      "Requirement already satisfied: google-cloud-bigquery!=2.4.*,<4.0.0dev,>=1.27.2 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from pandas_gbq) (2.30.1)\n",
      "Requirement already satisfied: google-cloud-bigquery-storage<3.0.0dev,>=1.1.0 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from pandas_gbq) (2.9.1)\n",
      "Requirement already satisfied: pyarrow<9.0dev,>=3.0.0 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from pandas_gbq) (8.0.0)\n",
      "Requirement already satisfied: google-auth>=1.25.0 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from pandas_gbq) (2.3.3)\n",
      "Requirement already satisfied: setuptools in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from pandas_gbq) (57.4.0)\n",
      "Requirement already satisfied: pandas>=0.24.2 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from pandas_gbq) (1.3.4)\n",
      "Requirement already satisfied: pydata-google-auth in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from pandas_gbq) (1.2.0)\n",
      "Requirement already satisfied: google-auth-oauthlib>=0.0.1 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from pandas_gbq) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from pandas_gbq) (1.20.3)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from pandas_gbq) (2.7.3)\n",
      "Collecting pyarrow<9.0dev,>=3.0.0\n",
      "  Using cached pyarrow-6.0.1-cp38-cp38-macosx_10_13_x86_64.whl (19.1 MB)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from db-dtypes<2.0.0,>=0.3.1->pandas_gbq) (21.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.52.0 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->pandas_gbq) (1.53.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->pandas_gbq) (2.26.0)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->pandas_gbq) (3.19.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from google-auth>=1.25.0->pandas_gbq) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from google-auth>=1.25.0->pandas_gbq) (4.2.4)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from google-auth>=1.25.0->pandas_gbq) (1.16.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from google-auth>=1.25.0->pandas_gbq) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from google-auth-oauthlib>=0.0.1->pandas_gbq) (1.3.0)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from google-cloud-bigquery!=2.4.*,<4.0.0dev,>=1.27.2->pandas_gbq) (2.1.0)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.4.1 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from google-cloud-bigquery!=2.4.*,<4.0.0dev,>=1.27.2->pandas_gbq) (2.1.0)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from google-cloud-bigquery!=2.4.*,<4.0.0dev,>=1.27.2->pandas_gbq) (2.8.2)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.38.1 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from google-cloud-bigquery!=2.4.*,<4.0.0dev,>=1.27.2->pandas_gbq) (1.41.1)\n",
      "Requirement already satisfied: proto-plus>=1.10.0 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from google-cloud-bigquery!=2.4.*,<4.0.0dev,>=1.27.2->pandas_gbq) (1.19.7)\n",
      "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->pandas_gbq) (1.41.1)\n",
      "Requirement already satisfied: libcst>=0.2.5 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from google-cloud-bigquery-storage<3.0.0dev,>=1.1.0->pandas_gbq) (0.3.21)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery!=2.4.*,<4.0.0dev,>=1.27.2->pandas_gbq) (1.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.2 in /Users/nfiguera/anaconda3/lib/python3.8/site-packages (from libcst>=0.2.5->google-cloud-bigquery-storage<3.0.0dev,>=1.1.0->pandas_gbq) (5.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.2 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from libcst>=0.2.5->google-cloud-bigquery-storage<3.0.0dev,>=1.1.0->pandas_gbq) (3.10.0.2)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from libcst>=0.2.5->google-cloud-bigquery-storage<3.0.0dev,>=1.1.0->pandas_gbq) (0.7.1)\n",
      "Requirement already satisfied: pyparsing<3,>=2.0.2 in /Users/nfiguera/anaconda3/lib/python3.8/site-packages (from packaging>=17.0->db-dtypes<2.0.0,>=0.3.1->pandas_gbq) (2.4.7)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from pandas>=0.24.2->pandas_gbq) (2021.3)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.25.0->pandas_gbq) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->pandas_gbq) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->pandas_gbq) (2.0.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->pandas_gbq) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->pandas_gbq) (1.26.7)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.0.1->pandas_gbq) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/nfiguera/anaconda3/lib/python3.8/site-packages (from typing-inspect>=0.4.0->libcst>=0.2.5->google-cloud-bigquery-storage<3.0.0dev,>=1.1.0->pandas_gbq) (0.4.3)\n",
      "Installing collected packages: pyarrow, pandas-gbq\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 8.0.0\n",
      "    Uninstalling pyarrow-8.0.0:\n",
      "      Successfully uninstalled pyarrow-8.0.0\n",
      "  Attempting uninstall: pandas-gbq\n",
      "    Found existing installation: pandas-gbq 0.17.5\n",
      "    Uninstalling pandas-gbq-0.17.5:\n",
      "      Successfully uninstalled pandas-gbq-0.17.5\n",
      "Successfully installed pandas-gbq-0.17.6 pyarrow-6.0.1\n"
     ]
    }
   ],
   "source": [
    "read_from_gsheet = True\n",
    "\n",
    "#only execute if we want to run the gsheet upload / download\n",
    "if read_from_gsheet:\n",
    "    !{sys.executable} -m pip install  pygsheets\n",
    "    !{sys.executable} -m pip install --upgrade pyarrow\n",
    "    !{sys.executable} -m pip install --upgrade google.cloud\n",
    "    !{sys.executable} -m pip install --upgrade pandas_gbq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edea41d9-b0a0-415d-998a-9e7c0f3b8312",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages/snowflake/connector/options.py:94: UserWarning: You have an incompatible version of 'pyarrow' installed (6.0.1), please install a version that adheres to: 'pyarrow<5.1.0,>=5.0.0; extra == \"pandas\"'\n",
      "  warn_incompatible_dep(\n"
     ]
    }
   ],
   "source": [
    "#get data\n",
    "import pygsheets\n",
    "import configparser\n",
    "import sys\n",
    "import snowflake.connector\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np                   # v 1.19.2\n",
    "import matplotlib.pyplot as plt      # v 3.3.2\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.ticker as ticker\n",
    "# calculate the net_arr bucket of open deals\n",
    "import seaborn as sns\n",
    "from math import floor \n",
    "from datetime import date\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from gitlabdata.orchestration_utils import (\n",
    "    data_science_engine_factory,\n",
    "    query_dataframe,\n",
    ")\n",
    "\n",
    "engine = data_science_engine_factory()\n",
    "\n",
    "service_file_path = 'nfiguera-c3fe9e64-a6543dd51e79.json'\n",
    "\n",
    "#target gsheet for uploads and downloads, just allowing one to keep it more secure\n",
    "spreadsheet_id = '19PPoHdc5nRZRX3dKGeGyYyTwqZ_x7GwD3EaDnwVm9Xs'\n",
    "\n",
    "#how to add access to gsheet\n",
    "#https://stackoverflow.com/questions/62917910/python-export-pandas-dataframe-to-google-sheets-solved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f4c2be1-0340-4882-8c6d-2d2361574b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_gsheet(service_file_path, spreadsheet_id, sheet_name, data_df):\n",
    "    \"\"\"\n",
    "    this function takes data_df and writes it under spreadsheet_id\n",
    "    and sheet_name using your credentials under service_file_path\n",
    "    \"\"\"\n",
    "    gc = pygsheets.authorize(service_file=service_file_path)\n",
    "    sh = gc.open_by_key(spreadsheet_id)\n",
    "    try:\n",
    "        sh.add_worksheet(sheet_name)\n",
    "    except:\n",
    "        pass\n",
    "    wks_write = sh.worksheet_by_title(sheet_name)\n",
    "    wks_write.clear('A1',None,'*')\n",
    "    wks_write.set_dataframe(data_df, (1,1), encoding='utf-8', fit=True)\n",
    "    wks_write.frozen_rows = 1\n",
    "\n",
    "def read_from_gsheet(service_file_path, spreadsheet_id, sheet_name):\n",
    "    \"\"\"\n",
    "    this function takes a sheet_name from a spreadsheet_id and returns a data frame \n",
    "    \"\"\"\n",
    "    gc = pygsheets.authorize(service_file=service_file_path)\n",
    "    sh = gc.open_by_key(spreadsheet_id)\n",
    "   \n",
    "    wks_read = sh.worksheet_by_title(sheet_name)\n",
    "    read = wks_read.get_as_df()\n",
    "    \n",
    "    return read\n",
    "\n",
    "\n",
    "def run_query_in_snowflake(conn, sql):\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(sql)\n",
    "    df = cur.fetch_pandas_all()\n",
    "    return df\n",
    "\n",
    "def executeScriptFromFile(filename, engine):\n",
    "    # Open and read the file as a single buffer\n",
    "    fd = open(filename, 'r')\n",
    "    sqlFile = fd.read()\n",
    "    fd.close()\n",
    "    \n",
    "    results = -1\n",
    "    \n",
    "    try:\n",
    "        results = query_dataframe(engine,sqlFile)\n",
    "    except:\n",
    "        print(\"Command did not run\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "###########################################################\n",
    "\n",
    "def days_between(d1, d2):\n",
    "    #d1 = datetime.strptime(d1, \"%Y-%m-%d\")\n",
    "    #d2 = datetime.strptime(d2, \"%Y-%m-%d\")\n",
    "    return (d2 - d1).days\n",
    "\n",
    "\n",
    "def calculate_quarters_after_creation(x):\n",
    "        \n",
    "    age = 0\n",
    "    \n",
    "    if (x['IS_OPEN'] == 1):\n",
    "        age = days_between(x['CREATED_FISCAL_QUARTER_DATE'], x['SNAPSHOT_FISCAL_QUARTER_DATE'])\n",
    "    elif (x['IS_OPEN']== 0 and x['SNAPSHOT_DATE'] <= x['CLOSE_DATE']):\n",
    "        age = days_between(x['CREATED_FISCAL_QUARTER_DATE'], x['SNAPSHOT_FISCAL_QUARTER_DATE'])\n",
    "    else:\n",
    "        age = days_between(x['CREATED_FISCAL_QUARTER_DATE'], x['CLOSE_FISCAL_QUARTER_DATE'])\n",
    "    \n",
    "    quarter_delta = floor(age/90)\n",
    "    \n",
    "    return quarter_delta\n",
    "\n",
    "def calculate_channel_track (x):\n",
    "    \n",
    "    channel_track = 'Direct'\n",
    "    \n",
    "    if (x['deal_path'] == 'Direct'):\n",
    "        channel_track = 'Direct'\n",
    "    elif (x['deal_path'] == 'Web Direct'):\n",
    "        channel_track = 'Web Direct'\n",
    "    elif (x['deal_path'] == 'Channel'\n",
    "        and x['sales_qualified_source'] != 'Channel Generated'): \n",
    "        channel_track = 'Partner Co-Sell'\n",
    "    elif (x['deal_path'] == 'Channel'):\n",
    "        channel_track = 'Partner Sourced'\n",
    "    \n",
    "    return channel_track\n",
    "\n",
    "def dt_inplace(df):\n",
    "    \"\"\"Automatically detect and convert (in place!) each\n",
    "    dataframe column of datatype 'object' to a datetime just\n",
    "    when ALL of its non-NaN values can be successfully parsed\n",
    "    by pd.to_datetime().  Also returns a ref. to df for\n",
    "    convenient use in an expression.\n",
    "    \"\"\"\n",
    "    for c in df.columns[df.dtypes=='object']: #don't cnvt num\n",
    "        try:\n",
    "            df[c]=pd.to_datetime(df[c])\n",
    "        except: #Can't cnvrt some\n",
    "            try: \n",
    "                df[c]=df[c].astype(str)\n",
    "            except:\n",
    "                pass # ...so leave whole column as-is unconverted\n",
    "            \n",
    "    for c in df.columns[df.dtypes=='bool']: #don't cnvt num\n",
    "        try: \n",
    "            df[c]=df[c].astype(int)\n",
    "        except:\n",
    "            pass # ...so leave whole column as-is unconverted\n",
    "    return df\n",
    "\n",
    "def join_column_to_df (df, source_df, key, key_source,target_column, rename_column):\n",
    "    \n",
    "    index = [key_source,target_column]\n",
    "    df = df.merge(source_df[index],how='left',left_on=key,right_on=key_source)\n",
    "    df.drop(key_source,axis=1,inplace=True)\n",
    "    df.rename(columns={target_column:rename_column}, inplace=True)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f12859c3-a950-4f53-9fc7-27f617121a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#capture regions to country\n",
    "#only execute if we want to run the gsheet upload / download\n",
    "if read_from_gsheet:\n",
    "    sheet_name = 'input_country_to_region'\n",
    "    country_to_region = read_from_gsheet(service_file_path, spreadsheet_id, sheet_name)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4abb9b1f-b3a1-465c-80c8-f74b303b1a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#capture regions to country\n",
    "#only execute if we want to run the gsheet upload / download\n",
    "if read_from_gsheet:\n",
    "    sheet_name = 'input_gitlab_industry_perc_it_spent'\n",
    "    gitlab_industry_it_spent = read_from_gsheet(service_file_path, spreadsheet_id, sheet_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6270d7af-b049-458d-9242-263868cc04e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command did not run\n"
     ]
    }
   ],
   "source": [
    "base_emea_accounts_summary = executeScriptFromFile('account_summary.sql', engine)\n",
    "#base_emea_accounts_summary.to_csv('account_summary.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07d8ea30-de78-4850-99a0-dd9504844392",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'merge'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/cd/7kp87vcs3jb7rj0n6_fkv96r0000gp/T/ipykernel_15748/232842967.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0memea_accounts_summary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_emea_accounts_summary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcountry_to_region\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sfdc_country'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'comm_region'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mleft_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'account_country'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mright_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sfdc_country'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0memea_accounts_summary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sfdc_country'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0memea_accounts_summary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"comm_region\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"account_region\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0memea_accounts_summary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memea_accounts_summary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcountry_to_region\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sfdc_country'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'comm_sub_region'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mleft_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'upa_country'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mright_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sfdc_country'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'merge'"
     ]
    }
   ],
   "source": [
    "\n",
    "emea_accounts_summary = base_emea_accounts_summary.merge(country_to_region[['sfdc_country','comm_region']],how='left',left_on='account_country',right_on='sfdc_country')\n",
    "emea_accounts_summary.drop('sfdc_country',axis=1,inplace=True)\n",
    "emea_accounts_summary.rename(columns={\"comm_region\":\"account_region\"}, inplace=True)\n",
    "\n",
    "emea_accounts_summary = emea_accounts_summary.merge(country_to_region[['sfdc_country','comm_sub_region']],how='left',left_on='upa_country',right_on='sfdc_country')\n",
    "emea_accounts_summary.drop('sfdc_country',axis=1,inplace=True)\n",
    "emea_accounts_summary.rename(columns={\"comm_sub_region\":\"upa_sub_region\"}, inplace=True)\n",
    "\n",
    "emea_accounts_summary = emea_accounts_summary.merge(country_to_region[['sfdc_country','comm_region']],how='left',left_on='upa_country',right_on='sfdc_country')\n",
    "emea_accounts_summary.drop('sfdc_country',axis=1,inplace=True)\n",
    "emea_accounts_summary.rename(columns={\"comm_region\":\"upa_region\"}, inplace=True)\n",
    "\n",
    "emea_accounts_summary = emea_accounts_summary.merge(country_to_region[['sfdc_country','comm_region']],how='left',left_on='upa_country',right_on='sfdc_country')\n",
    "emea_accounts_summary.drop('sfdc_country',axis=1,inplace=True)\n",
    "emea_accounts_summary.rename(columns={\"comm_region\":\"upa_fy23_region\"}, inplace=True)\n",
    "\n",
    "emea_accounts_summary['technical_account_manager_date'] = pd.to_datetime(emea_accounts_summary['technical_account_manager_date'])\n",
    "\n",
    "#it industry spent\n",
    "emea_accounts_summary = emea_accounts_summary.merge(gitlab_industry_it_spent[['gitlab_industry','it_spend_perc']],how='left',left_on='account_industry',right_on='gitlab_industry')\n",
    "emea_accounts_summary.drop('gitlab_industry',axis=1,inplace=True)\n",
    "emea_accounts_summary.rename(columns={\"it_spend_perc\":\"account_it_spend_perc\"}, inplace=True)\n",
    "#replace nans with blanks\n",
    "emea_accounts_summary[['upa_region','account_region','upa_fy23_region']] = emea_accounts_summary[['upa_region','account_region','upa_fy23_region']].replace(np.nan,'',regex=True)\n",
    "emea_accounts_summary['account_potential_tam'] = emea_accounts_summary['zi_revenue'] * emea_accounts_summary['account_it_spend_perc'] * 0.1 * 0.2\n",
    "emea_accounts_summary['technical_account_manager_date'] = pd.to_datetime(emea_accounts_summary['technical_account_manager_date'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f166dc-104f-4282-99ca-8fee3b2b5b98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#accounts_summaryDict = dict(emea_accounts_summary.dtypes)\n",
    "#accounts_summaryDict\n",
    "emea_accounts_summary.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb13c63-5ff3-4b84-877b-6a544eabfec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "# I like pandas gbq because it can infer schema\n",
    "# https://pandas-gbq.readthedocs.io/en/latest/writing.html#inferring-the-table-schema\n",
    "import pandas_gbq\n",
    "\n",
    "# path to your json key file\n",
    "KEY_PATH = \"nfiguera_big_query.json\"\n",
    "\n",
    "# TODO: Set project_id to your Google Cloud Platform project ID.\n",
    "project_id = \"nfiguera-c3fe9e64\"\n",
    "\n",
    "# TODO: Set table_id to the full destination table ID (including the\n",
    "#       dataset ID).\n",
    "table_id = 'nfiguera-c3fe9e64.proto.report_large_accounts_metrics'\n",
    "\n",
    "# read the credentials from our file\n",
    "# scopes are not necessary because we defined them in GCP already\n",
    "CREDS = service_account.Credentials.from_service_account_file(KEY_PATH)\n",
    "\n",
    "pandas_gbq.to_gbq(emea_accounts_summary, table_id, if_exists = 'replace', project_id=project_id, credentials = CREDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9fe9bf-f4d2-45e4-bb40-328000c48ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(emea_accounts_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3896d966-6f29-447c-a654-2e3d74cb2b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfdc_opportunity = executeScriptFromFile('sfdc_opportunity.sql', engine)\n",
    "sfdc_opportunity.to_csv('sfdc_opportunity.csv')\n",
    "\n",
    "dt_inplace(sfdc_opportunity)\n",
    "#sfdc_opportunity_dict = dict(sfdc_opportunity.dtypes)\n",
    "#sfdc_opportunity_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d78d61b-a8f5-4a9c-8c4d-6bcc83c2875a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add start date per rep\n",
    "sfdc_opportunity_new = join_column_to_df(sfdc_opportunity,country_to_region,'account_billing_country','sfdc_country','comm_region','account_region')\n",
    "sfdc_opportunity_new = join_column_to_df(sfdc_opportunity_new,country_to_region,'upa_billing_country','sfdc_country','comm_region','upa_region')\n",
    "sfdc_opportunity_new = join_column_to_df(sfdc_opportunity_new,country_to_region,'account_billing_country','sfdc_country','comm_sub_region','account_sub_region')\n",
    "sfdc_opportunity_new = join_column_to_df(sfdc_opportunity_new,country_to_region,'upa_billing_country','sfdc_country','comm_sub_region','upa_sub_region')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1c2865-3744-4d35-ae2f-9e9290236ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "# I like pandas gbq because it can infer schema\n",
    "# https://pandas-gbq.readthedocs.io/en/latest/writing.html#inferring-the-table-schema\n",
    "import pandas_gbq\n",
    "\n",
    "# path to your json key file\n",
    "KEY_PATH = \"nfiguera_big_query.json\"\n",
    "\n",
    "# TODO: Set project_id to your Google Cloud Platform project ID.\n",
    "project_id = \"nfiguera-c3fe9e64\"\n",
    "\n",
    "# TODO: Set table_id to the full destination table ID (including the\n",
    "#       dataset ID).\n",
    "table_id = 'nfiguera-c3fe9e64.proto.sfdc_opportunity_xf'\n",
    "\n",
    "# read the credentials from our file\n",
    "# scopes are not necessary because we defined them in GCP already\n",
    "CREDS = service_account.Credentials.from_service_account_file(KEY_PATH)\n",
    "\n",
    "pandas_gbq.to_gbq(sfdc_opportunity_new, table_id, if_exists = 'replace', project_id=project_id, credentials = CREDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5142a1df-432f-468a-9450-61a4f04cf130",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "ea4f0e1d1faa5bb96f695d7e31ce7a9817f73b9836258768e692d46b900aef52"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
