## SaaS Service Ping

SaaS `Service Ping` (formerly known as `usage ping`) is collected from self-installed instances of GitLab for those instances that have the feature enabled. This feature allows GitLab to understand usage data for self-installed instances broken down on an instance and namespace level.

`GitLab.com`, which is essentially a GitLab-hosted version of `GitLab`, has sent usage ping data in the past, but this process had problems:
* The service ping process from `GitLab.com` took too long to run _(6-8 hours on average)_
* Running the same queries in the SaaS instance as other instances resulted in data that was not granular enough. Data was needed from the namespace grain for better analytics.

This extract addresses these issues:  

* This extract offloads the SaaS service ping process in `Airflow` and `Snowflake`, it doesn't take production resources to complete.  The queries may still be long-running and costly, but `Snowflake` is much better suited for large data transformations such as the service ping queries.  Additionally, the data team can monitor durations and costs on this draft dashboard [here](https://app.periscopedata.com/app/gitlab/839683/SaaS-Usage-Ping-Monitoring) to ensure that the costs stay within acceptable bounds. 

* This extract runs queries for the namespace level so that metrics can be gathered in fine enough detail to serve the product and technical account manager teams.

Please review the [public-facing handbook page for SaaS Service Ping](https://about.gitlab.com/handbook/business-technology/data-team/data-catalog/saas-service-ping-automation/) for more information about this process.

### Technical Implementation
There are 3 relevant data structures:
- SaaS SQL service ping: generated from running a series of `SQL` queries
- Redis ping: data from the `Redis` instance, obtained from an API endpoint
- Combined: The output of the 'SQL' and 'Redis' data-structures are combined. This is the only data persisted into Snowflake.

The below sub-sections cover each of the three data-structures in more detail.

#### SaaS SQL service ping
The SaaS service pings are generated by iterating through a series of `SQL` queries and running them in the `Snowflake` data warehouse. 
Data in `Snowflake` schema `RAW.TAP_POSTGRES` are nothing but a mimic from `Postgres` replica we loaded under another `DAG'.


`SQL` queries we executed on `RAW.TAP_POSTGRES` the schema are translated from `Postgres` to `Snowflake` SQL syntax.
The results of the queries are then uploaded into the `RAW.SAAS_USAGE_PING` schema in Snowflake database _(data is stored in `.json` file format)_.  

`SQL data` is originally saved in `Postgres Sql` syntax format, downloaded using `RESTful API` technology: The queries are version controlled in the very large `.json` files present within this extract. The queries are split out into two categories: 
- `instance queries` and 
- `namespace queries`. 
    
The `instance queries` generate data about GitLab.com as a whole, while the `namespace queries` generate data about each namespace on GitLab.com.
Data is stored in the table: 
- `RAW.SAAS_USAGE_PING.INSTANCE_SQL_METRICS` - this data is generated results of `SQL` queries. 
    - Note: this is table is deprecated as of Nov 2022,  as only the `combined` metrics are persisted into Snowflake in the table `INSTANCE_COMBINED_METRICS`.
- `RAW.SAAS_USAGE_PING.INSTANCE_SQL_ERROR` - this table contains `SQL` commands where error pops-up with the error description. If there is any record in this table, means some `SQL` query failed with an execution and the `Data team` will be alerted - via logs in `Airflow` and in [Trusted data framework (`TDF`)](https://about.gitlab.com/handbook/business-technology/data-team/platform/#tdf). 
- `RAW.SAAS_USAGE_PING.GITLAB_DOTCOM_NAMESPACE` - namespace data is stored in this table 

##### Graphical representation of the pipeline for `INSTANCE_SQL_METRICS`:
```mermaid
graph TD;
  PGREP[Postgres replica]--Store data from Postgres-->SF_TP[Snowflake RAW.TAP_POSTGRES];
  SP_API[[Service ping API]]--Call API-->DNLD(Download data);
  DNLD--Translate syntax-->TR_SQL[Translate SQL from Postgres -> Snowflake syntax];
  DNLD--Keep metadata-->MTD[Store meta data in .json];
  MTD--Save meta data-->FIN_RAW;
  TR_SQL--Execute queries-->SF_TP;
  SF_TP-->ERROR_CHECK{Metrics generated?}--Yes-->FIN_RAW(Preserve SQL metrics results - to combine with Instance Redis Metrics later);
  ERROR_CHECK--No-->ERR(Generate error record in RAW.SAAS_USAGE_PING.INSTANCE_SQL_ERROR);
```

#### Redis data

One more kind of data is uploaded for the `service_ping` - data from `Redis` instance are also uploaded using `RESTful API` technology . 
`Redis data` is picked up and stored in a `.json` format, with an approximate size is around `2k` lines, usually one file per load _(at the moment, it is a weekly load)_.

The main purpose of loading data from Redis is to ensure fine granulation of metrics.

Data is stored in the table:
- `RAW.SAAS_USAGE_PING.INSTANCE_REDIS_METRICS` - this data is generated results of `RESTful API` call
    - Note: this is table is deprecated as of Nov 2022,  as only the `combined` metrics are persisted into Snowflake in the table `INSTANCE_COMBINED_METRICS`.
    
##### Graphical representation of the pipeline for `INSTANCE_REDIS_METRICS`:
```mermaid
graph TD;
  SP_API[[Redis API]]--Call API-->DNLD(Download data);
  DNLD--Keep metadata-->MTD[Store meta data in .json];
  MTD--Save meta data-->FIN_RAW;
  DNLD--Store data-->FIN_RAW(Preserve Redis metrics results - to combine with Instance SQL Metrics later);
```
        
#### Combined data
In order to allow for easier downstream processing of the `redis` and `sql` data, the two payloads are now *combined*.

To prevent duplicates metrics when combining the two payloads, every metric from both payloads is compared against a `metrics_definitions.yml` file, which serves as the source of truth of the 'correct' metric data-source.

Data is stored in the table:
- `RAW.SAAS_USAGE_PING.COMBINED_METRICS`

##### Graphical representation of the pipeline for `INSTANCE_COMBINED_METRICS`:
```mermaid
graph LR
subgraph Combining Metrics
A[1.1: SQL metrics result] --- C[ ]:::empty  
B[1.2: Redis metrics result] --- C
C --> D[2: Combine results]
D --> E[3: Store in Snowflake RAW COMBINED_METRICS]
classDef empty width:0px,height:0px;
end
```

### Backfilling SaaS Service Ping

There is also a process in place to recreate SaaS service pings from the past.

There is a separate backfill `DAG` that allows back filling service pings for the last `12` months.

The process backfills by filtering the queries to only those that query over a specific timeframe defined in the `NAMESPACE_BACKFILL_VAR` variable in the `Airflow`,
and then passing in the month it is backfilling for as the timeframe.

#### Namespace backfill

In order to backfill particular metric (or set of them), need to add `NAMESPACE_BACKFILL_VAR` in the `Airflow`.

The example how variable `NAMESPACE_BACKFILL_VAR` should look like:
```json
{
 "start_date": "2022-10-01",
 "end_date": "2022-11-25",
 "metrics_backfill": "['usage_activity_by_stage_monthly.manage.project_imports.git','usage_activity_by_stage_monthly.manage.groups_with_event_streaming_destinations','usage_activity_by_stage_monthly.manage.audit_event_destinations','counts.boards']"
}
```

The `saas_usage_ping_backfill`  `DAG` will backfill data for the metrics where the following conditions are applied: 
* For the defined period (`start_date` and `end_date` value from `NAMESPACE_BACKFILL_VAR` variable)
* `"time_window_query": true` - `time_window_query` variable. This variable is stored in the `.json` file `usage_ping_namespace_queries.json` and predefined along with other metrics details. One example for namespace metrics definition is:
    ```json{
     ...
     "counter_name": "counts.operations_dashboard_users_with_projects_added",
     "counter_query": "SELECT 1",
     "time_window_query": false,
     "level": "namespace"
    },
    {
     "counter_name": "counts_monthly.deployments",
     "counter_query": "SELECT 1 FROM table WHERE created_at BETWEEN between_start_date AND between_end_date",
     "time_window_query": true,
     "level": "namespace"
    }
    ...
    ```
  
    The `time_window_query` variable determines do we have time-specific filter (`time_window_query=true`) and need to replace placeholders or not (`time_window_query=false`). If `time_window_query=false`, we are talking about **all-time** metrics. 
* The desired metric(s) to be backfilled need to be included within the `NAMESPACE_BACKFILL_VAR` variable, specifically as one of the list values in the `metrics_backfill` key.

